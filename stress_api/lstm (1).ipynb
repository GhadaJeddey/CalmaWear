{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy pandas scikit-learn pyhrv wfdb torch torchvision tqdm kagglehub\n",
        "!pip install kagglehub torch numpy scipy scikit-learn\n",
        "!pip install peakutils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrNdi6_xGatw",
        "outputId": "1611dae6-29d6-4be3-b1a9-aa853fb2cd83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting pyhrv\n",
            "  Downloading pyhrv-0.4.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting biosppy (from pyhrv)\n",
            "  Downloading biosppy-2.2.4-py2.py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pyhrv) (3.10.0)\n",
            "Collecting nolds (from pyhrv)\n",
            "  Downloading nolds-0.6.3-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting spectrum (from pyhrv)\n",
            "  Downloading spectrum-0.9.0.tar.gz (231 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.2)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyhrv) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyhrv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyhrv) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyhrv) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyhrv) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.11.12)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Collecting bidict (from biosppy->pyhrv)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from biosppy->pyhrv) (3.15.1)\n",
            "Collecting shortuuid (from biosppy->pyhrv)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from biosppy->pyhrv) (4.12.0.88)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.12/dist-packages (from biosppy->pyhrv) (1.9.0)\n",
            "Collecting mock (from biosppy->pyhrv)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from nolds->pyhrv) (1.0.0)\n",
            "Collecting easydev (from spectrum->pyhrv)\n",
            "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from easydev->spectrum->pyhrv)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog<7.0.0,>=6.8.2 (from easydev->spectrum->pyhrv)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum->pyhrv)\n",
            "  Downloading line_profiler-4.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from easydev->spectrum->pyhrv) (4.9.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from easydev->spectrum->pyhrv) (4.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum->pyhrv) (0.7.0)\n",
            "Downloading pyhrv-0.4.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biosppy-2.2.4-py2.py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nolds-0.6.3-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading easydev-0.13.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading line_profiler-4.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (720 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m720.1/720.1 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spectrum\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.9.0-cp312-cp312-linux_x86_64.whl size=236769 sha256=76d5bc34bf24a054473ad84dc2bb4ee6c0deea75840a0f4265da5735fcce3c56\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a0/e0/e04656d89dd723adbe6ea41ab5fe702f5d4ccf95653eb54b04\n",
            "Successfully built spectrum\n",
            "Installing collected packages: shortuuid, nolds, mock, line-profiler, colorlog, colorama, bidict, pandas, easydev, wfdb, spectrum, biosppy, pyhrv\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bidict-0.23.1 biosppy-2.2.4 colorama-0.4.6 colorlog-6.10.1 easydev-0.13.3 line-profiler-4.2.0 mock-5.2.0 nolds-0.6.3 pandas-2.3.3 pyhrv-0.4.1 shortuuid-1.0.13 spectrum-0.9.0 wfdb-4.3.0\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Collecting peakutils\n",
            "  Downloading PeakUtils-1.3.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from peakutils) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from peakutils) (1.16.3)\n",
            "Downloading PeakUtils-1.3.5-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: peakutils\n",
            "Successfully installed peakutils-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0uxtqhPVFvUh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy import stats\n",
        "import pyhrv.time_domain as td\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = kagglehub.dataset_download(\n",
        "    \"orvile/wesad-wearable-stress-affect-detection-dataset\"\n",
        ")\n",
        "\n",
        "DATA_PATH = os.path.join(root_path, \"WESAD\")\n",
        "\n",
        "print(\"DATA_PATH:\", DATA_PATH)\n",
        "print(\"Subjects:\", os.listdir(DATA_PATH))\n",
        "\n",
        "\n",
        "def load_subject(sid: str):\n",
        "    p = os.path.join(DATA_PATH, f\"S{sid}\", f\"S{sid}.pkl\")\n",
        "    with open(p, \"rb\") as f:\n",
        "        data = pickle.load(f, encoding=\"latin1\")\n",
        "\n",
        "    chest = data[\"signal\"][\"chest\"]\n",
        "\n",
        "    ecg  = chest[\"ECG\"].reshape(-1)\n",
        "    resp = chest[\"Resp\"].reshape(-1)\n",
        "    acc  = chest[\"ACC\"]          # (N,3)\n",
        "    labels = data[\"label\"].reshape(-1)\n",
        "\n",
        "    return {\n",
        "        \"ecg\": ecg,\n",
        "        \"resp\": resp,\n",
        "        \"acc\": acc,\n",
        "        \"label\": labels,\n",
        "    }\n",
        "\n",
        "# sanity check\n",
        "s2 = load_subject(\"2\")\n",
        "print(\"ECG:\", s2[\"ecg\"].shape)\n",
        "print(\"RESP:\", s2[\"resp\"].shape)\n",
        "print(\"ACC:\", s2[\"acc\"].shape)\n",
        "print(\"LABEL:\", s2[\"label\"].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0PxroqKFxAQ",
        "outputId": "2f21c487-5744-4df9-a976-30b5aa874db1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'wesad-wearable-stress-affect-detection-dataset' dataset.\n",
            "DATA_PATH: /kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD\n",
            "Subjects: ['S14', 'S11', 'S13', 'S10', 'S8', 'S5', 'S7', 'S9', 'S15', 'wesad_readme.pdf', 'S2', 'S6', 'S3', 'S4', 'S16', 'S17']\n",
            "ECG: (4255300,)\n",
            "RESP: (4255300,)\n",
            "ACC: (4255300, 3)\n",
            "LABEL: (4255300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(ecg_win, resp_win, acc_win, fs=700.0, win_seconds=10.0):\n",
        "    # ACC magnitude\n",
        "    acc_mag = np.linalg.norm(acc_win, axis=1)\n",
        "\n",
        "    # ECG peaks ‚Üí HR + HRV\n",
        "    peaks, _ = find_peaks(ecg_win, distance=int(0.3 * fs))\n",
        "    rr = np.diff(peaks) / fs\n",
        "\n",
        "    mean_hr = 60.0 / np.mean(rr) if len(rr) > 1 else 0.0\n",
        "\n",
        "    try:\n",
        "        rmssd = td.rmssd(rr)['rmssd'] if len(rr) > 2 else 0.0\n",
        "    except:\n",
        "        rmssd = 0.0\n",
        "\n",
        "    # Respiration rate (Hz)\n",
        "    resp_peaks, _ = find_peaks(resp_win, distance=int(0.5 * fs))\n",
        "    breathing_rate = len(resp_peaks) / win_seconds\n",
        "\n",
        "    # ACC variance\n",
        "    acc_var = float(np.var(acc_mag))\n",
        "\n",
        "    return np.array([mean_hr, rmssd, breathing_rate, acc_var], dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "pJ9Sh6fTFyXY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset_for_subject(sid: str, window_size=7000, step=3500):\n",
        "    s = load_subject(sid)\n",
        "    ecg, resp, acc, labels = s[\"ecg\"], s[\"resp\"], s[\"acc\"], s[\"label\"]\n",
        "\n",
        "    Xs, ys = [], []\n",
        "\n",
        "    for start in range(0, len(ecg) - window_size, step):\n",
        "        end = start + window_size\n",
        "\n",
        "        ecg_w  = ecg[start:end]\n",
        "        resp_w = resp[start:end]\n",
        "        acc_w  = acc[start:end]\n",
        "\n",
        "        feats = extract_features(ecg_w, resp_w, acc_w)\n",
        "\n",
        "        # Majority label in this window\n",
        "        label_mode = stats.mode(labels[start:end], keepdims=False)[0]\n",
        "\n",
        "        Xs.append(feats)\n",
        "        ys.append(label_mode)\n",
        "\n",
        "    return np.vstack(Xs), np.array(ys, dtype=int)\n"
      ],
      "metadata": {
        "id": "T3jjGPyBF8DX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = [\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"13\",\"14\",\"15\",\"16\",\"17\"]\n",
        "\n",
        "X_subjects = {}\n",
        "y_subjects = {}\n",
        "\n",
        "for sid in subjects:\n",
        "    print(f\"Processing S{sid}...\")\n",
        "    Xs, ys = build_dataset_for_subject(sid)\n",
        "    X_subjects[sid] = Xs          # (n_windows, 4)\n",
        "    y_subjects[sid] = ys          # (n_windows,)\n",
        "\n",
        "# Convert labels to binary: stress = label 2\n",
        "STRESS_LABELS = [2]\n",
        "\n",
        "y_subjects_bin = {\n",
        "    sid: np.isin(y_subjects[sid], STRESS_LABELS).astype(int)\n",
        "    for sid in subjects\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1wfSFZnF89Q",
        "outputId": "26f0ad9b-e598-405d-a32b-cb019210504e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing S2...\n",
            "Processing S3...\n",
            "Processing S4...\n",
            "Processing S5...\n",
            "Processing S6...\n",
            "Processing S7...\n",
            "Processing S8...\n",
            "Processing S9...\n",
            "Processing S10...\n",
            "Processing S11...\n",
            "Processing S13...\n",
            "Processing S14...\n",
            "Processing S15...\n",
            "Processing S16...\n",
            "Processing S17...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all windows to compute scaling\n",
        "X_all_raw = np.vstack([X_subjects[sid] for sid in subjects])\n",
        "\n",
        "PHYS_MEAN = X_all_raw.mean(axis=0).astype(np.float32)\n",
        "PHYS_STD  = X_all_raw.std(axis=0).astype(np.float32)\n",
        "\n",
        "print(\"PHYS_MEAN:\", PHYS_MEAN)\n",
        "print(\"PHYS_STD :\", PHYS_STD)\n",
        "\n",
        "def phys_scale(X):\n",
        "    return (X - PHYS_MEAN) / PHYS_STD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86vX1HzVF-_X",
        "outputId": "367987cf-dd9a-454f-cd0b-03ef906f3780"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PHYS_MEAN: [1.53799377e+02 1.25880196e+02 1.87475598e+00 6.02732180e-04]\n",
            "PHYS_STD : [1.3753248e+01 5.1713493e+01 7.9733528e-02 1.4178814e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 10      # number of windows per sequence\n",
        "SEQ_STEP = 1      # stride between sequences\n",
        "\n",
        "def build_sequences_for_subject(X_raw, y_bin, seq_len=SEQ_LEN, seq_step=SEQ_STEP):\n",
        "    # Scale the features\n",
        "    X = phys_scale(X_raw)\n",
        "\n",
        "    X_seqs = []\n",
        "    y_seqs = []\n",
        "\n",
        "    n = len(X)\n",
        "    for start in range(0, n - seq_len, seq_step):\n",
        "        end = start + seq_len\n",
        "\n",
        "        seq_feats = X[start:end]         # (seq_len, 4)\n",
        "        seq_labels = y_bin[start:end]    # (seq_len,)\n",
        "\n",
        "        # Label for the sequence = majority of window labels\n",
        "        label_mode = stats.mode(seq_labels, keepdims=False)[0]\n",
        "\n",
        "        X_seqs.append(seq_feats)\n",
        "        y_seqs.append(label_mode)\n",
        "\n",
        "    return np.stack(X_seqs), np.array(y_seqs, dtype=int)  # (n_seq, seq_len, 4), (n_seq,)\n"
      ],
      "metadata": {
        "id": "mpg3F17PF_WX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_seq_all = []\n",
        "y_seq_all = []\n",
        "\n",
        "for sid in subjects:\n",
        "    X_raw = X_subjects[sid]\n",
        "    y_bin = y_subjects_bin[sid]\n",
        "\n",
        "    Xs, ys = build_sequences_for_subject(X_raw, y_bin)\n",
        "    X_seq_all.append(Xs)\n",
        "    y_seq_all.append(ys)\n",
        "    print(f\"Subject S{sid}: sequences={Xs.shape[0]}\")\n",
        "\n",
        "X_seq_all = np.vstack(X_seq_all)  # (N_seq, SEQ_LEN, 4)\n",
        "y_seq_all = np.concatenate(y_seq_all)\n",
        "\n",
        "print(\"Final sequence dataset:\", X_seq_all.shape, y_seq_all.shape)\n",
        "print(\"Binary labels (sequence level):\", np.unique(y_seq_all, return_counts=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIZ8HkPNGApH",
        "outputId": "cf593c69-c987-46d6-c80a-10a32fb9e8c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject S2: sequences=1204\n",
            "Subject S3: sequences=1287\n",
            "Subject S4: sequences=1273\n",
            "Subject S5: sequences=1240\n",
            "Subject S6: sequences=1403\n",
            "Subject S7: sequences=1036\n",
            "Subject S8: sequences=1082\n",
            "Subject S9: sequences=1033\n",
            "Subject S10: sequences=1088\n",
            "Subject S11: sequences=1035\n",
            "Subject S13: sequences=1096\n",
            "Subject S14: sequences=1098\n",
            "Subject S15: sequences=1039\n",
            "Subject S16: sequences=1115\n",
            "Subject S17: sequences=1172\n",
            "Final sequence dataset: (17201, 10, 4) (17201,)\n",
            "Binary labels (sequence level): (array([0, 1]), array([15222,  1979]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_seq_all, y_seq_all,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_seq_all\n",
        ")\n",
        "\n",
        "print(\"Train seqs:\", X_train.shape, y_train.shape)\n",
        "print(\"Test  seqs:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dezuVLYIGCt3",
        "outputId": "4701a13e-493e-4265-b93b-18a7d127ebf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seqs: (13760, 10, 4) (13760,)\n",
            "Test  seqs: (3441, 10, 4) (3441,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StressSeqDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_ds = StressSeqDataset(X_train, y_train)\n",
        "test_ds  = StressSeqDataset(X_test,  y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "3yGkJfLIGFIQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class StressLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dim=64, num_layers=1, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, input_dim)\n",
        "        out, (h_n, c_n) = self.lstm(x)\n",
        "        # Take last hidden state: (batch, hidden_dim)\n",
        "        h_last = h_n[-1]\n",
        "        logits = self.fc(h_last)\n",
        "        return logits\n",
        "\n",
        "model = StressLSTM().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKPRukwQGF5b",
        "outputId": "a9d62fd8-eb4f-411d-b1c8-565c74240b2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class weights at sequence level\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2gOQZ62GFgZ",
        "outputId": "fc14010c-9d82-4ad8-d57b-9abc9725c744"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: tensor([0.5650, 4.3462], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 150\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for Xb, yb in train_loader:\n",
        "        Xb = Xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(Xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_loss = total_loss / total\n",
        "    train_acc  = correct / total\n",
        "\n",
        "    if epoch % 5 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | Loss={train_loss:.4f} | Train Acc={train_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld70ZfuHGFwx",
        "outputId": "bcdf84df-3fd7-4539-87cb-2943dc64860e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Loss=0.4887 | Train Acc=0.772\n",
            "Epoch 005 | Loss=0.4068 | Train Acc=0.788\n",
            "Epoch 010 | Loss=0.3703 | Train Acc=0.801\n",
            "Epoch 015 | Loss=0.3561 | Train Acc=0.794\n",
            "Epoch 020 | Loss=0.3355 | Train Acc=0.801\n",
            "Epoch 025 | Loss=0.3081 | Train Acc=0.810\n",
            "Epoch 030 | Loss=0.2910 | Train Acc=0.821\n",
            "Epoch 035 | Loss=0.2822 | Train Acc=0.828\n",
            "Epoch 040 | Loss=0.2599 | Train Acc=0.838\n",
            "Epoch 045 | Loss=0.2358 | Train Acc=0.856\n",
            "Epoch 050 | Loss=0.2284 | Train Acc=0.859\n",
            "Epoch 055 | Loss=0.2218 | Train Acc=0.863\n",
            "Epoch 060 | Loss=0.2140 | Train Acc=0.866\n",
            "Epoch 065 | Loss=0.2002 | Train Acc=0.875\n",
            "Epoch 070 | Loss=0.1930 | Train Acc=0.881\n",
            "Epoch 075 | Loss=0.1888 | Train Acc=0.884\n",
            "Epoch 080 | Loss=0.1829 | Train Acc=0.888\n",
            "Epoch 085 | Loss=0.1780 | Train Acc=0.890\n",
            "Epoch 090 | Loss=0.1764 | Train Acc=0.892\n",
            "Epoch 095 | Loss=0.1722 | Train Acc=0.894\n",
            "Epoch 100 | Loss=0.1714 | Train Acc=0.898\n",
            "Epoch 105 | Loss=0.1675 | Train Acc=0.897\n",
            "Epoch 110 | Loss=0.1674 | Train Acc=0.898\n",
            "Epoch 115 | Loss=0.1640 | Train Acc=0.900\n",
            "Epoch 120 | Loss=0.1632 | Train Acc=0.898\n",
            "Epoch 125 | Loss=0.1623 | Train Acc=0.902\n",
            "Epoch 130 | Loss=0.1622 | Train Acc=0.902\n",
            "Epoch 135 | Loss=0.1596 | Train Acc=0.901\n",
            "Epoch 140 | Loss=0.1613 | Train Acc=0.902\n",
            "Epoch 145 | Loss=0.1606 | Train Acc=0.903\n",
            "Epoch 150 | Loss=0.1580 | Train Acc=0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for Xb, yb in test_loader:\n",
        "        Xb = Xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        logits = model(Xb)\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(yb.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "print(classification_report(all_labels, all_preds, digits=3))\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjam95paGKGW",
        "outputId": "961279b6-da74-4454-83dc-368ee7ef733b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.984     0.882     0.930      3045\n",
            "           1      0.495     0.886     0.635       396\n",
            "\n",
            "    accuracy                          0.883      3441\n",
            "   macro avg      0.739     0.884     0.783      3441\n",
            "weighted avg      0.927     0.883     0.896      3441\n",
            "\n",
            "[[2687  358]\n",
            " [  45  351]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sequence_stress(raw_seq_2d):\n",
        "    \"\"\"\n",
        "    raw_seq_2d: np.array of shape (SEQ_LEN, 4)\n",
        "                with raw [HR, RMSSD, breathing, acc_var]\n",
        "    \"\"\"\n",
        "    # Scale with PHYS_MEAN/STD\n",
        "    scaled = phys_scale(raw_seq_2d).astype(np.float32)\n",
        "    x = torch.tensor(scaled.reshape(1, SEQ_LEN, 4), dtype=torch.float32).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        prob = torch.softmax(logits, dim=1)[0,1].item()\n",
        "        stress_percent = prob * 100.0\n",
        "    return stress_percent\n"
      ],
      "metadata": {
        "id": "k8t6_pgdGJmm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rule_based_correction(hr, rmssd, breath, movement, lstm_stress):\n",
        "    stress = float(lstm_stress)\n",
        "\n",
        "    # 1Ô∏è‚É£ Sport / exercise\n",
        "    if movement >= 0.8 and rmssd > 35:\n",
        "        stress = min(stress, 15)\n",
        "        return stress, 0\n",
        "\n",
        "    # 2Ô∏è‚É£ Panic / crisis\n",
        "    if hr > 120 and rmssd < 8 and movement < 0.4:\n",
        "        stress = max(stress, 90)\n",
        "        return stress, 3\n",
        "\n",
        "    # 3Ô∏è‚É£ High mental stress\n",
        "    if hr > 100 and rmssd < 20 and movement < 0.4:\n",
        "        stress = max(stress, 70)\n",
        "        return stress, 2\n",
        "\n",
        "    # 4Ô∏è‚É£ Sleep / deep rest\n",
        "    if hr < 60 and rmssd > 70 and movement < 0.15:\n",
        "        stress = min(stress, 5)\n",
        "        return stress, 0\n",
        "\n",
        "    # 5Ô∏è‚É£ Light activity / walking / talking\n",
        "    if movement > 0.5 and rmssd > 30:\n",
        "        stress = min(stress, 35)\n",
        "        return stress, 1\n",
        "\n",
        "    # 6Ô∏è‚É£ Default: trust LSTM\n",
        "    stress = max(0, min(stress, 100))\n",
        "\n",
        "    # Map to level\n",
        "    if stress < 20:\n",
        "        return stress, 0\n",
        "    elif stress < 40:\n",
        "        return stress, 1\n",
        "    elif stress < 70:\n",
        "        return stress, 2\n",
        "    else:\n",
        "        return stress, 3\n"
      ],
      "metadata": {
        "id": "482t0F4CN2t5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_single(hr, rmssd, breath, movement):\n",
        "    \"\"\"\n",
        "    Run LSTM on a single physiological snapshot.\n",
        "    Returns stress percentage (0‚Äì100).\n",
        "    \"\"\"\n",
        "\n",
        "    # Build sequence\n",
        "    raw_seq = np.tile([hr, rmssd, breath, movement], (SEQ_LEN, 1))\n",
        "\n",
        "    # Normalize\n",
        "    scaled = (raw_seq - PHYS_MEAN) / PHYS_STD\n",
        "\n",
        "    # Tensor ‚Üí SAME DEVICE AS MODEL\n",
        "    x = torch.tensor(\n",
        "        scaled,\n",
        "        dtype=torch.float32,\n",
        "        device=device   # üî• THIS FIXES THE ERROR\n",
        "    ).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    return probs[0, 1].item() * 100\n",
        "\n"
      ],
      "metadata": {
        "id": "2y6IADmB_A0o"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_predict(hr, rmssd, breath, movement):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      stress_pct (float): 0‚Äì100\n",
        "      level (int): 0‚Äì3\n",
        "    \"\"\"\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 1Ô∏è‚É£ Get LSTM prediction\n",
        "    # --------------------------------------------------\n",
        "    lstm_stress = predict_single(hr, rmssd, breath, movement)  # 0‚Äì100\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 2Ô∏è‚É£ If LSTM is untrained / collapsed ‚Üí use heuristic base\n",
        "    # --------------------------------------------------\n",
        "    if lstm_stress < 5:   # VERY IMPORTANT LINE\n",
        "        # Physiological baseline stress estimation\n",
        "        base = 0\n",
        "\n",
        "        # HR contribution\n",
        "        if hr > 110: base += 35\n",
        "        elif hr > 95: base += 25\n",
        "        elif hr > 80: base += 10\n",
        "\n",
        "        # HRV contribution\n",
        "        if rmssd < 15: base += 35\n",
        "        elif rmssd < 25: base += 20\n",
        "        elif rmssd < 40: base += 10\n",
        "\n",
        "        # Breathing contribution\n",
        "        if breath > 0.6: base += 20\n",
        "        elif breath > 0.4: base += 10\n",
        "\n",
        "        # Clamp\n",
        "        stress = min(base, 60)\n",
        "\n",
        "    else:\n",
        "        stress = lstm_stress\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 3Ô∏è‚É£ Rule-based correction (your fixed version)\n",
        "    # --------------------------------------------------\n",
        "\n",
        "    # Sport / exercise\n",
        "    if movement >= 0.8 and rmssd > 35:\n",
        "        stress = min(stress, 15)\n",
        "        return stress, 0\n",
        "\n",
        "    # Panic\n",
        "    if hr > 120 and rmssd < 8 and movement < 0.4:\n",
        "        stress = max(stress, 90)\n",
        "        return stress, 3\n",
        "\n",
        "    # High mental stress\n",
        "    if hr > 100 and rmssd < 20 and movement < 0.4:\n",
        "        stress = max(stress, 70)\n",
        "        return stress, 2\n",
        "\n",
        "    # Sleep\n",
        "    if hr < 60 and rmssd > 70 and movement < 0.15:\n",
        "        stress = min(stress, 5)\n",
        "        return stress, 0\n",
        "\n",
        "    # Walking / light activity\n",
        "    if movement > 0.5 and rmssd > 30:\n",
        "        stress = min(stress, 35)\n",
        "        return stress, 1\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 4Ô∏è‚É£ Final level mapping\n",
        "    # --------------------------------------------------\n",
        "    if stress < 20:\n",
        "        return stress, 0\n",
        "    elif stress < 40:\n",
        "        return stress, 1\n",
        "    elif stress < 70:\n",
        "        return stress, 2\n",
        "    else:\n",
        "        return stress, 3\n"
      ],
      "metadata": {
        "id": "QPKEg-5VN3_Y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tn43bQpVN5xp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0  # any index in [0, len(X_test)-1]\n",
        "raw_seq = X_test[i] * PHYS_STD + PHYS_MEAN  # back to raw\n",
        "print(\"Stress %:\", predict_sequence_stress(raw_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kadsn4cSGJbZ",
        "outputId": "45b18852-1b88-4e91-9166-1b6d1fd96423"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stress %: 0.001125711696658982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- CALM SEQUENCE (SEQ_LEN x 4) ----\n",
        "calm_seq = np.tile(\n",
        "    np.array([72, 45, 0.25, 0.10]),   # HR, RMSSD, Breath, ACCvar\n",
        "    (SEQ_LEN, 1)\n",
        ")\n",
        "\n",
        "print(\"Calm Stress %:\", predict_sequence_stress(calm_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgu_-UqjIANY",
        "outputId": "7a71c150-0dda-4012-c150-7feeb986a344"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calm Stress %: 2.390024374631229e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- STRESS SEQUENCE ----\n",
        "stress_seq = np.tile(\n",
        "    np.array([115, 10, 0.65, 1.20]),  # High HR, low RMSSD, fast breathing, movement\n",
        "    (SEQ_LEN, 1)\n",
        ")\n",
        "\n",
        "print(\"Stress Stress %:\", predict_sequence_stress(stress_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHxF6ri9IXaM",
        "outputId": "e6ad9dea-5f9c-468c-e2cc-f8762cc94918"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stress Stress %: 99.62318539619446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- TRANSITION SEQUENCE (first half calm, second half stress) ----\n",
        "half = SEQ_LEN // 2\n",
        "\n",
        "transition_seq = np.vstack([\n",
        "    np.tile(np.array([72, 45, 0.25, 0.10]), (half, 1)),     # calm half\n",
        "    np.tile(np.array([110, 12, 0.60, 1.10]), (SEQ_LEN-half, 1))  # stress half\n",
        "])\n",
        "\n",
        "print(\"Transition Stress %:\", predict_sequence_stress(transition_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saq7ARybIaSG",
        "outputId": "e1cd294f-58cf-471e-de80-430265a90851"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transition Stress %: 0.1723736640997231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calm_feat = np.array([72, 45, 0.25, 0.10])\n",
        "calm_seq = np.tile(calm_feat, (SEQ_LEN, 1))\n",
        "print(\"LSTM Calm %:\", predict_sequence_stress(calm_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B97BIbeAQaI",
        "outputId": "62775f5f-4bd1-4d7e-a1c3-6f0e66802b5c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Calm %: 2.390024374631229e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stress_feat = np.array([115, 10, 0.65, 1.20])\n",
        "\n",
        "stress_seq = np.tile(stress_feat, (SEQ_LEN, 1))\n",
        "print(\"LSTM Stress %:\", predict_sequence_stress(stress_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AroRgngbCgrF",
        "outputId": "4dce70ab-d1b4-4ec2-81cd-fba55414f2a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Stress %: 99.62318539619446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "half = SEQ_LEN // 2\n",
        "\n",
        "transition_seq = np.vstack([\n",
        "    np.tile(np.array([72, 45, 0.25, 0.10]), (half, 1)),\n",
        "    np.tile(np.array([110, 12, 0.60, 1.10]), (SEQ_LEN-half, 1))\n",
        "])\n",
        "# LSTM sees whole history\n",
        "print(\"LSTM Transition %:\",\n",
        "      predict_sequence_stress(transition_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnvzymGSChQ_",
        "outputId": "4e7ee4fb-e0f3-43ce-8dbb-6e028e964344"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Transition %: 0.1723736640997231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recovery_seq = np.vstack([\n",
        "    np.tile(np.array([110, 12, 0.60, 1.10]), (half, 1)),\n",
        "    np.tile(np.array([75, 40, 0.30, 0.15]), (SEQ_LEN-half, 1))\n",
        "])\n",
        "print(\"LSTM Recovery %:\", predict_sequence_stress(recovery_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76tLQ2NvCsiB",
        "outputId": "c0fdb2f6-8e6a-4791-d6af-efb6c31d9a84"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Recovery %: 3.295528048586141e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sport_feat = np.array([150, 120, 1.8, 0.9])\n",
        "\n",
        "sport_seq = np.tile(sport_feat, (SEQ_LEN, 1))\n",
        "print(\"LSTM Sport %:\", predict_sequence_stress(sport_seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKSFDuUtC0QP",
        "outputId": "76660de9-e994-4dff-b150-06b7e133b7c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Sport %: 99.99489784240723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j = np.random.randint(0, len(X_test))  # for LSTM\n",
        "raw_seq = X_test[j] * PHYS_STD + PHYS_MEAN\n",
        "print(j)\n",
        "print(\"\\n--- LSTM REAL TEST ---\")\n",
        "print(\"True:\", y_test[j])\n",
        "print(\"LSTM %:\", predict_sequence_stress(raw_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPCJZhO3C9Li",
        "outputId": "a27c9985-7501-4f24-d6f4-0745f8fc85ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "811\n",
            "\n",
            "--- LSTM REAL TEST ---\n",
            "True: 0\n",
            "LSTM %: 5.158036764091607e-21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases (ready to use)\n",
        "test_cases = {\n",
        "    \"deep_sleep\":    [55,  75,  0.20, 0.05],  # ‚Üí 2%\n",
        "    \"calm\":          [72,  45,  0.25, 0.10],  # ‚Üí 0%\n",
        "    \"light_active\":  [85,  35,  0.35, 0.20],  # ‚Üí <25%\n",
        "    \"moderate_stress\": [95, 22, 0.50, 0.30],  # ‚Üí 40-60%\n",
        "    \"high_stress\":   [110, 12,  0.60, 0.25],  # ‚Üí 75%\n",
        "    \"panic\":         [130, 7,   0.90, 0.15],  # ‚Üí 95%\n",
        "    \"walking\":       [105, 35,  0.70, 0.60],  # ‚Üí 20-40%\n",
        "    \"sport\":         [150, 120, 1.80, 0.90],  # ‚Üí 5%\n",
        "}"
      ],
      "metadata": {
        "id": "-tOiEDDO_45I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test all cases quickly\n",
        "for name, vals in {\n",
        "    \"deep_sleep\": [55, 75, 0.20, 0.05],\n",
        "    \"calm\": [72, 45, 0.25, 0.10],\n",
        "    \"light_active\": [85, 35, 0.35, 0.20],\n",
        "    \"moderate_stress\": [95, 22, 0.50, 0.30],\n",
        "    \"high_stress\": [110, 12, 0.60, 0.25],\n",
        "    \"panic\": [130, 7, 0.90, 0.15],\n",
        "    \"walking\": [105, 35, 0.70, 0.60],\n",
        "    \"sport\": [150, 120, 1.80, 0.90]\n",
        "}.items():\n",
        "    pct, lvl = safe_predict(*vals)\n",
        "    print(f\"{name:18} ‚Üí {pct:6.2f}% (Level {lvl})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w33JYAvxmZ0n",
        "outputId": "6987a12f-e44c-419d-eeae-0e402942588e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep_sleep         ‚Üí   0.00% (Level 0)\n",
            "calm               ‚Üí   0.00% (Level 0)\n",
            "light_active       ‚Üí  20.00% (Level 1)\n",
            "moderate_stress    ‚Üí  40.00% (Level 2)\n",
            "high_stress        ‚Üí  70.00% (Level 2)\n",
            "panic              ‚Üí  90.00% (Level 3)\n",
            "walking            ‚Üí  35.00% (Level 1)\n",
            "sport              ‚Üí  15.00% (Level 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlGhZGqFnHSq"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}